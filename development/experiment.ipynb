{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b26b58-8258-4df7-be9c-c1aa3980b82f",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34486e01-8ece-4d04-b02d-15c011111903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "def search_ticker(query):\n",
    "    stock = yf.Ticker(query)\n",
    "    info = stock.info\n",
    "    print(f\"Available attributes: {', '.join(info.keys())}\")\n",
    "    \n",
    "    print(f\"Ticker: {query}\")\n",
    "    print(f\"Short Name: {info.get('shortName', 'Not Found')}\")\n",
    "    print(f\"Long Name: {info.get('longName', 'Not Found')}\")\n",
    "    print(f\"Sector: {info.get('sector', 'Not Found')}\")\n",
    "    print(f\"Industry: {info.get('industry', 'Not Found')}\")\n",
    "    print(f\"Country: {info.get('country', 'Not Found')}\")\n",
    "    print(f\"Currency: {info.get('currency', 'Not Found')}\")\n",
    "    print(f\"Exchange: {info.get('exchange', 'Not Found')}\")\n",
    "    print(f\"Previous Close: {info.get('regularMarketPreviousClose', 'Not Found')}\")\n",
    "    print(f\"Market Cap: {info.get('marketCap', 'Not Found')}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf48845-9a8e-4455-90c5-67db65239d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: phone, maxAge, priceHint, previousClose, open, dayLow, dayHigh, regularMarketPreviousClose, regularMarketOpen, regularMarketDayLow, regularMarketDayHigh, volume, regularMarketVolume, averageVolume, averageVolume10days, averageDailyVolume10Day, bid, ask, totalAssets, fiftyTwoWeekLow, fiftyTwoWeekHigh, fiftyDayAverage, twoHundredDayAverage, navPrice, currency, ytdReturn, fundFamily, fundInceptionDate, legalType, threeYearAverageReturn, fiveYearAverageReturn, exchange, quoteType, symbol, underlyingSymbol, shortName, longName, firstTradeDateEpochUtc, timeZoneFullName, timeZoneShortName, uuid, messageBoardId, gmtOffSetMilliseconds, trailingPegRatio\n",
      "Ticker: 00631L.TW\n",
      "Short Name: YUANTA SECURITIES INV TRUST CO \n",
      "Long Name: Yuanta Daily Taiwan 50 Bull 2X ETF\n",
      "Sector: Not Found\n",
      "Industry: Not Found\n",
      "Country: Not Found\n",
      "Currency: TWD\n",
      "Exchange: TAI\n",
      "Previous Close: 207.05\n",
      "Market Cap: Not Found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search_ticker(\"AAPL\")\n",
    "# search_ticker(\"TSLA\")\n",
    "search_ticker(\"00631L.TW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd4aa1-0df9-4fa4-9bd0-e7d963e26809",
   "metadata": {},
   "source": [
    "# Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7e5fba7-de8b-4ac1-aa7d-c1f1d27f7f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col, avg, year\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\n\u001b[1;32m      7\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBacktesting 00631L Strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, year\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Backtesting 00631L Strategy\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f343ef-f3ff-4e22-b5b7-6791c6da98eb",
   "metadata": {},
   "source": [
    "# Load and Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a5563a-0290-40ff-a45e-542788c2e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in ./.venv/lib/python3.12/site-packages (0.2.38)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (69.5.1)\n",
      "Collecting distlib\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in ./.venv/lib/python3.12/site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.12/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.12/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.12/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in ./.venv/lib/python3.12/site-packages (from yfinance) (5.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in ./.venv/lib/python3.12/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in ./.venv/lib/python3.12/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./.venv/lib/python3.12/site-packages (from yfinance) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in ./.venv/lib/python3.12/site-packages (from yfinance) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./.venv/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in ./.venv/lib/python3.12/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: distlib\n",
      "Successfully installed distlib-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance setuptools distlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18164862-f0db-47ac-b2a8-213a2e7a55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetch_monthly_data(ticker):\n",
    "    # Fetch the data\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(period=\"max\")\n",
    "\n",
    "    # Resample to monthly data\n",
    "    monthly_data = hist.resample('ME').agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }).dropna()\n",
    "\n",
    "    return monthly_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    data.to_csv(filename, index=True)\n",
    "\n",
    "# Fetch and save the data\n",
    "ticker = \"00631L.TW\"\n",
    "monthly_data = fetch_monthly_data(ticker)\n",
    "save_to_csv(monthly_data, \"00631L_monthly_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0641db5f-813e-423e-bb59-7be690b1eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|year|        moving_avg|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+\n",
      "|2024-05-31 00:00:00|193.39999389648438|214.35000610351562|             192.0| 213.3000030517578| 17167616|2024|156.51666768391928|\n",
      "|2024-04-30 00:00:00|196.10000610351562|206.60000610351562|174.35000610351562|196.35000610351562| 77971912|2024| 149.4291674296061|\n",
      "|2024-03-31 00:00:00|170.89999389648438|198.10000610351562|169.60000610351562|194.64999389648438| 47924380|2024| 142.4708334604899|\n",
      "|2024-02-29 00:00:00|152.39999389648438|171.10000610351562|151.35000610351562|170.14999389648438| 22536440|2024|136.04166730244955|\n",
      "|2024-01-31 00:00:00|             152.0| 155.6999969482422|140.35000610351562|             152.0| 68343566|2024|131.18333435058594|\n",
      "|2023-12-31 00:00:00| 142.4499969482422|151.85000610351562| 140.8000030517578| 151.1999969482422| 53352811|2023|127.62500127156575|\n",
      "|2023-11-30 00:00:00|            123.25| 144.3000030517578| 121.6500015258789|             143.5| 82457447|2023|122.75833511352539|\n",
      "|2023-10-31 00:00:00|130.14999389648438|             135.5|             121.5|121.80000305175781| 79589929|2023|119.30833498636882|\n",
      "|2023-09-30 00:00:00|132.35000610351562|            136.75| 125.6500015258789|127.80000305175781| 57951559|2023|115.57083447774251|\n",
      "|2023-08-31 00:00:00| 141.4499969482422| 141.9499969482422| 126.1500015258789|132.35000610351562| 82370703|2023|111.85416730244954|\n",
      "|2023-07-31 00:00:00| 137.0500030517578|145.39999389648438| 130.8000030517578|139.85000610351562| 69463214|2023|109.62916692097981|\n",
      "|2023-06-30 00:00:00|126.94999694824219|140.85000610351562| 126.6500015258789|            135.25| 43529285|2023|106.65833282470703|\n",
      "|2023-05-31 00:00:00|113.05000305175781|            129.75|            110.75|            128.25| 61331494|2023|103.58333269755046|\n",
      "|2023-04-30 00:00:00|115.94999694824219|118.80000305175781| 109.0999984741211| 112.8499984741211| 43726284|2023| 103.0583324432373|\n",
      "|2023-03-31 00:00:00|             109.5|            118.75|107.30000305175781|             117.5| 84892545|2023|103.69583257039388|\n",
      "|2023-02-28 00:00:00|110.44999694824219|            114.75|108.80000305175781| 111.8499984741211| 61275924|2023|105.31666564941406|\n",
      "|2023-01-31 00:00:00|              91.5| 112.6500015258789|  90.4000015258789|109.30000305175781| 79242485|2023|107.36666552225749|\n",
      "|2022-12-31 00:00:00|             105.5|106.19999694824219| 90.30000305175781| 92.80000305175781|144784192|2022| 109.7458324432373|\n",
      "|2022-11-30 00:00:00| 76.94999694824219| 102.0999984741211| 75.69999694824219| 102.0999984741211|223174631|2022|114.17916552225749|\n",
      "|2022-10-31 00:00:00|  81.3499984741211|              89.5|  73.6500015258789| 76.94999694824219|249480309|2022|116.64583206176758|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 11:46:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"00631L_monthly_data.csv\"\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "data = data.withColumn(\"year\", year(\"date\"))\n",
    "\n",
    "# Create a temporary view\n",
    "data.createOrReplaceTempView(\"stock_base\")\n",
    "\n",
    "# Register a SQL query to calculate the 12-month moving average partitioned by year\n",
    "query = \"\"\"\n",
    "    SELECT *,\n",
    "           AVG(close) OVER (ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS moving_avg\n",
    "    FROM stock_base\n",
    "    ORDER BY `year` DESC, Date DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "stock_with_moving_avg = spark.sql(query)\n",
    "stock_with_moving_avg.createOrReplaceTempView(\"stock_with_moving_avg\")\n",
    "\n",
    "# Show the result\n",
    "stock_with_moving_avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5ea68-bbf5-42e7-b1c4-ce7b096e63b8",
   "metadata": {},
   "source": [
    "# Implement Purchase and Liquidation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0db4be-f928-4f37-b131-c9c728659f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+--------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|year|        moving_avg|action|holdings|holdings|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+--------+\n",
      "|2024-05-31 00:00:00|193.39999389648438|214.35000610351562|             192.0| 213.3000030517578| 17167616|2024|156.51666768391928|   buy|       0|      60|\n",
      "|2024-04-30 00:00:00|196.10000610351562|206.60000610351562|174.35000610351562|196.35000610351562| 77971912|2024| 149.4291674296061|   buy|       0|      59|\n",
      "|2024-03-31 00:00:00|170.89999389648438|198.10000610351562|169.60000610351562|194.64999389648438| 47924380|2024| 142.4708334604899|   buy|       0|      58|\n",
      "|2024-02-29 00:00:00|152.39999389648438|171.10000610351562|151.35000610351562|170.14999389648438| 22536440|2024|136.04166730244955|   buy|       0|      57|\n",
      "|2024-01-31 00:00:00|             152.0| 155.6999969482422|140.35000610351562|             152.0| 68343566|2024|131.18333435058594|   buy|       0|      56|\n",
      "|2023-12-31 00:00:00| 142.4499969482422|151.85000610351562| 140.8000030517578| 151.1999969482422| 53352811|2023|127.62500127156575|   buy|       0|      55|\n",
      "|2023-11-30 00:00:00|            123.25| 144.3000030517578| 121.6500015258789|             143.5| 82457447|2023|122.75833511352539|   buy|       0|      54|\n",
      "|2023-10-31 00:00:00|130.14999389648438|             135.5|             121.5|121.80000305175781| 79589929|2023|119.30833498636882|   buy|       0|      53|\n",
      "|2023-09-30 00:00:00|132.35000610351562|            136.75| 125.6500015258789|127.80000305175781| 57951559|2023|115.57083447774251|   buy|       0|      52|\n",
      "|2023-08-31 00:00:00| 141.4499969482422| 141.9499969482422| 126.1500015258789|132.35000610351562| 82370703|2023|111.85416730244954|   buy|       0|      51|\n",
      "|2023-07-31 00:00:00| 137.0500030517578|145.39999389648438| 130.8000030517578|139.85000610351562| 69463214|2023|109.62916692097981|   buy|       0|      50|\n",
      "|2023-06-30 00:00:00|126.94999694824219|140.85000610351562| 126.6500015258789|            135.25| 43529285|2023|106.65833282470703|   buy|       0|      49|\n",
      "|2023-05-31 00:00:00|113.05000305175781|            129.75|            110.75|            128.25| 61331494|2023|103.58333269755046|   buy|       0|      48|\n",
      "|2023-04-30 00:00:00|115.94999694824219|118.80000305175781| 109.0999984741211| 112.8499984741211| 43726284|2023| 103.0583324432373|   buy|       0|      47|\n",
      "|2023-03-31 00:00:00|             109.5|            118.75|107.30000305175781|             117.5| 84892545|2023|103.69583257039388|   buy|       0|      46|\n",
      "|2023-02-28 00:00:00|110.44999694824219|            114.75|108.80000305175781| 111.8499984741211| 61275924|2023|105.31666564941406|   buy|       0|      45|\n",
      "|2023-01-31 00:00:00|              91.5| 112.6500015258789|  90.4000015258789|109.30000305175781| 79242485|2023|107.36666552225749|   buy|       0|      44|\n",
      "|2022-12-31 00:00:00|             105.5|106.19999694824219| 90.30000305175781| 92.80000305175781|144784192|2022| 109.7458324432373|  sell|       0|      43|\n",
      "|2022-11-30 00:00:00| 76.94999694824219| 102.0999984741211| 75.69999694824219| 102.0999984741211|223174631|2022|114.17916552225749|  sell|       0|      44|\n",
      "|2022-10-31 00:00:00|  81.3499984741211|              89.5|  73.6500015258789| 76.94999694824219|249480309|2022|116.64583206176758|  sell|       0|      45|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Add actions using SQL\n",
    "actions_query = \"\"\"\n",
    "    SELECT *,\n",
    "           CASE\n",
    "               WHEN close >= moving_avg THEN 'buy'\n",
    "               WHEN close < moving_avg THEN 'sell'\n",
    "               ELSE ''\n",
    "           END AS action,\n",
    "           0 AS holdings -- Initialize holdings to 0\n",
    "    FROM stock_with_moving_avg\n",
    "\"\"\"\n",
    "\n",
    "result_with_actions = spark.sql(actions_query)\n",
    "result_with_actions.createOrReplaceTempView(\"stock_with_actions\")\n",
    "# result_with_actions.show(truncate=1000)\n",
    "\n",
    "# Update holdings based on actions\n",
    "holdings_query = \"\"\"\n",
    "    SELECT *,\n",
    "           SUM(CASE\n",
    "                   WHEN action = 'buy' THEN 1\n",
    "                   WHEN action = 'sell' THEN -1\n",
    "                   ELSE 0\n",
    "               END) OVER (ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS holdings\n",
    "    FROM stock_with_actions\n",
    "    ORDER BY `year` DESC, Date DESC\n",
    "\"\"\"\n",
    "\n",
    "result_with_strategy = spark.sql(holdings_query)\n",
    "result_with_strategy.show(truncate=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38458541-a247-4b37-8692-49b1dbcebaa3",
   "metadata": {},
   "source": [
    "# Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039cf76b-0e1e-4579-a9ae-997b0e84aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/15 11:46:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+------------+-----------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|year|        moving_avg|action|holdings|daily_return|cumulative_return|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+------------+-----------------+\n",
      "|2024-05-31 00:00:00|193.39999389648438|214.35000610351562|             192.0| 213.3000030517578| 17167616|2024|156.51666768391928|   buy|       0|         0.0|              0.0|\n",
      "|2024-04-30 00:00:00|196.10000610351562|206.60000610351562|174.35000610351562|196.35000610351562| 77971912|2024| 149.4291674296061|   buy|       0|         0.0|              0.0|\n",
      "|2024-03-31 00:00:00|170.89999389648438|198.10000610351562|169.60000610351562|194.64999389648438| 47924380|2024| 142.4708334604899|   buy|       0|         0.0|              0.0|\n",
      "|2024-02-29 00:00:00|152.39999389648438|171.10000610351562|151.35000610351562|170.14999389648438| 22536440|2024|136.04166730244955|   buy|       0|         0.0|              0.0|\n",
      "|2024-01-31 00:00:00|             152.0| 155.6999969482422|140.35000610351562|             152.0| 68343566|2024|131.18333435058594|   buy|       0|         0.0|              0.0|\n",
      "|2023-12-31 00:00:00| 142.4499969482422|151.85000610351562| 140.8000030517578| 151.1999969482422| 53352811|2023|127.62500127156575|   buy|       0|         0.0|              0.0|\n",
      "|2023-11-30 00:00:00|            123.25| 144.3000030517578| 121.6500015258789|             143.5| 82457447|2023|122.75833511352539|   buy|       0|         0.0|              0.0|\n",
      "|2023-10-31 00:00:00|130.14999389648438|             135.5|             121.5|121.80000305175781| 79589929|2023|119.30833498636882|   buy|       0|         0.0|              0.0|\n",
      "|2023-09-30 00:00:00|132.35000610351562|            136.75| 125.6500015258789|127.80000305175781| 57951559|2023|115.57083447774251|   buy|       0|         0.0|              0.0|\n",
      "|2023-08-31 00:00:00| 141.4499969482422| 141.9499969482422| 126.1500015258789|132.35000610351562| 82370703|2023|111.85416730244954|   buy|       0|         0.0|              0.0|\n",
      "|2023-07-31 00:00:00| 137.0500030517578|145.39999389648438| 130.8000030517578|139.85000610351562| 69463214|2023|109.62916692097981|   buy|       0|         0.0|              0.0|\n",
      "|2023-06-30 00:00:00|126.94999694824219|140.85000610351562| 126.6500015258789|            135.25| 43529285|2023|106.65833282470703|   buy|       0|         0.0|              0.0|\n",
      "|2023-05-31 00:00:00|113.05000305175781|            129.75|            110.75|            128.25| 61331494|2023|103.58333269755046|   buy|       0|         0.0|              0.0|\n",
      "|2023-04-30 00:00:00|115.94999694824219|118.80000305175781| 109.0999984741211| 112.8499984741211| 43726284|2023| 103.0583324432373|   buy|       0|         0.0|              0.0|\n",
      "|2023-03-31 00:00:00|             109.5|            118.75|107.30000305175781|             117.5| 84892545|2023|103.69583257039388|   buy|       0|         0.0|              0.0|\n",
      "|2023-02-28 00:00:00|110.44999694824219|            114.75|108.80000305175781| 111.8499984741211| 61275924|2023|105.31666564941406|   buy|       0|         0.0|              0.0|\n",
      "|2023-01-31 00:00:00|              91.5| 112.6500015258789|  90.4000015258789|109.30000305175781| 79242485|2023|107.36666552225749|   buy|       0|         0.0|              0.0|\n",
      "|2022-12-31 00:00:00|             105.5|106.19999694824219| 90.30000305175781| 92.80000305175781|144784192|2022| 109.7458324432373|  sell|       0|        -0.0|              0.0|\n",
      "|2022-11-30 00:00:00| 76.94999694824219| 102.0999984741211| 75.69999694824219| 102.0999984741211|223174631|2022|114.17916552225749|  sell|       0|         0.0|              0.0|\n",
      "|2022-10-31 00:00:00|  81.3499984741211|              89.5|  73.6500015258789| 76.94999694824219|249480309|2022|116.64583206176758|  sell|       0|        -0.0|              0.0|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+----+------------------+------+--------+------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Calculate returns\n",
    "returns_query = \"\"\"\n",
    "    SELECT *,\n",
    "           CASE\n",
    "               WHEN action = 'sell' THEN (close - LAG(close, 1) OVER (PARTITION BY year ORDER BY date)) * holdings\n",
    "               ELSE 0\n",
    "           END AS daily_return\n",
    "    FROM stock_with_actions\n",
    "    ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "result_with_returns = spark.sql(returns_query)\n",
    "result_with_returns.createOrReplaceTempView(\"stock_with_returns\")\n",
    "\n",
    "# Calculate cumulative returns\n",
    "cumulative_returns_query = \"\"\"\n",
    "    SELECT *,\n",
    "           SUM(daily_return) OVER (ORDER BY date) AS cumulative_return\n",
    "    FROM stock_with_returns\n",
    "    ORDER BY `year` DESC, Date DESC\n",
    "\"\"\"\n",
    "\n",
    "result_with_cumulative_returns = spark.sql(cumulative_returns_query)\n",
    "result_with_cumulative_returns.show(truncate=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1cf1c-b7ac-424b-82fa-e3f7906cc9b2",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f05e091-d186-47cc-9960-7eacac3a57f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pandas_df \u001b[38;5;241m=\u001b[39m \u001b[43mresult_with_cumulative_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Plot the closing price and moving average\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Development/financial-strategy-experiment/development/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/conversion.py:86\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _create_converter_to_pandas\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_minimum_pandas_version\n\u001b[0;32m---> 86\u001b[0m \u001b[43mrequire_minimum_pandas_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     90\u001b[0m jconf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession\u001b[38;5;241m.\u001b[39m_jconf\n",
      "File \u001b[0;32m~/Desktop/Development/financial-strategy-experiment/development/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/utils.py:24\u001b[0m, in \u001b[0;36mrequire_minimum_pandas_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TODO(HyukjinKwon): Relocate and deduplicate the version specification.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m minimum_pandas_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "pandas_df = result_with_cumulative_returns.toPandas()\n",
    "\n",
    "# Plot the closing price and moving average\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pandas_df['date'], pandas_df['close'], label='Closing Price')\n",
    "plt.plot(pandas_df['date'], pandas_df['moving_avg'], label='12-Month Moving Average', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Closing Price and Moving Average')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the cumulative returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pandas_df['date'], pandas_df['cumulative_return'], label='Cumulative Return', color='green')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.title('Cumulative Return of the Strategy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f448d7e4-2f26-48ab-82a1-8e2178e7105d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pandas_df \u001b[38;5;241m=\u001b[39m \u001b[43mresult_with_cumulative_returns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Development/financial-strategy-experiment/development/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/conversion.py:86\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _create_converter_to_pandas\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_minimum_pandas_version\n\u001b[0;32m---> 86\u001b[0m \u001b[43mrequire_minimum_pandas_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     90\u001b[0m jconf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession\u001b[38;5;241m.\u001b[39m_jconf\n",
      "File \u001b[0;32m~/Desktop/Development/financial-strategy-experiment/development/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/utils.py:24\u001b[0m, in \u001b[0;36mrequire_minimum_pandas_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TODO(HyukjinKwon): Relocate and deduplicate the version specification.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m minimum_pandas_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "pandas_df = result_with_cumulative_returns.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132d95d-5aac-45d1-941e-15ffe24bd905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
